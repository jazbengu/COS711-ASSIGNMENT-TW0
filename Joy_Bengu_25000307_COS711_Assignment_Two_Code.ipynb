{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazbengu/COS711-ASSIGNMENT-TWO/blob/main/Joy_Bengu_25000307_COS711_Assignment_Two_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrD_3efB3VAd",
        "collapsed": true,
        "outputId": "d097d2ea-4ad6-4a62-d78b-ef0c67691ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "#!pip install --force-reinstall tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ub8o5M6J18ES"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.optimizers import Optimizer\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8hKOKPFT2tzY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    data.iloc[:, :-1] = imputer.fit_transform(data.iloc[:, :-1])  # Assuming last column is labels\n",
        "\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "\n",
        "    y = pd.get_dummies(y).values\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RProp(Optimizer):\n",
        "    def __init__(self, learning_rate=0.01, **kwargs):\n",
        "        super(RProp, self).__init__(learning_rate=learning_rate, **kwargs)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.eta_plus = 1.2\n",
        "        self.eta_minus = 0.5\n",
        "        self.delta_min = 1e-6\n",
        "        self.delta_max = 50\n",
        "        self.delta_zero = 0.1\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        updates = []\n",
        "        for param, grad in zip(params, grads):\n",
        "            delta = K.variable(self.delta_zero, dtype=K.dtype(param))\n",
        "            delta_prev = K.variable(self.delta_zero, dtype=K.dtype(param))\n",
        "            grad_prev = K.variable(K.zeros_like(param), dtype=K.dtype(param))\n",
        "            updates.append((delta, K.switch(K.greater(grad * grad_prev, 0), K.minimum(delta * self.eta_plus, self.delta_max), K.maximum(delta * self.eta_minus, self.delta_min))))\n",
        "            updates.append((delta_prev, delta))\n",
        "            updates.append((grad_prev, grad))\n",
        "            updates.append((param, param - K.sign(grad) * delta))\n",
        "        return updates\n",
        "\n",
        "    def update_step(self, gradient, variable, learning_rate):\n",
        "        delta = K.variable(self.delta_zero, dtype=K.dtype(variable))\n",
        "        delta_prev = K.variable(self.delta_zero, dtype=K.dtype(variable))\n",
        "        grad_prev = K.variable(K.zeros_like(variable), dtype=K.dtype(variable))\n",
        "        delta_new = K.switch(K.greater(gradient * grad_prev, 0), K.minimum(delta * self.eta_plus, self.delta_max), K.maximum(delta * self.eta_minus, self.delta_min))\n",
        "        variable_new = variable - K.sign(gradient) * delta_new\n",
        "        return variable_new, delta_new, grad_prev\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'learning_rate': self.learning_rate}\n",
        "        base_config = super(RProp, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "QZVJjzfug2_H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PgrMZoS22txz"
      },
      "outputs": [],
      "source": [
        "def create_model(optimizer='adam', learning_rate=0.001, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=13, activation=activation))  # 12 input features\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dense(3, activation='softmax'))  # 3 classes\n",
        "\n",
        "    # Initialize the optimizer based on the chosen or default optimizer type\n",
        "    if optimizer == 'adam':\n",
        "        # Providing a default learning rate for Adam if not specified\n",
        "        learning_rate = learning_rate or 0.001\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        # Providing a default learning rate for SGD if not specified\n",
        "        learning_rate = learning_rate or 0.001\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    elif optimizer == 'rprop':  # Use RProp Optimizer\n",
        "       opt = RProp(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer type\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l64YbG4F2qVb"
      },
      "outputs": [],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "def perform_grid_search(X_train, y_train):\n",
        "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "    param_grid = {\n",
        "        'batch_size': [10, 20],\n",
        "        'epochs': [5, 10],\n",
        "        'optimizer': ['adam', 'sgd', 'rprop'],  # Add 'rprop'\n",
        "        'model__learning_rate': [0.001, 0.01],  # Note: RProp doesn't use learning rate\n",
        "        'model__activation': ['relu']\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "    grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "    # Plotting results\n",
        "    results_df = pd.DataFrame(grid_result.cv_results_)\n",
        "    results_pivot = results_df.pivot_table(index='param_batch_size', columns='param_epochs', values='mean_test_score')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(results_pivot, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
        "    plt.title(\"Hyperparameter Tuning: Batch Size vs Epochs\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Batch Size\")\n",
        "    plt.show()\n",
        "\n",
        "    return grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOYstehSbuM7"
      },
      "outputs": [],
      "source": [
        "def train_and_compare_algorithms(X_train, y_train, X_test, y_test):\n",
        "    adam_model = create_model(optimizer='adam', learning_rate=0.001)\n",
        "    history_adam = adam_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    sgd_model = create_model(optimizer='sgd', learning_rate=0.001)\n",
        "    history_sgd = sgd_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    rprop_model = create_model(optimizer='rprop', learning_rate=0.001)\n",
        "    history_rprop = rprop_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    plt.plot(history_adam.history['val_loss'], label='Adam')\n",
        "    plt.plot(history_sgd.history['val_loss'], label='SGD')\n",
        "    plt.plot(history_rprop.history['val_loss'], label='Rprop')\n",
        "    plt.title('Validation Loss Comparison')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Y2MwLlv2juY"
      },
      "outputs": [],
      "source": [
        "def hybrid_learning(X_train, y_train, X_test, y_test):\n",
        "    # Train individual models\n",
        "    adam_model = create_model(optimizer='adam', learning_rate=0.001)\n",
        "    adam_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    sgd_model = create_model(optimizer='sgd', learning_rate=0.001)\n",
        "    sgd_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    rprop_model = create_model(optimizer='rprop')\n",
        "    rprop_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    # Ensemble predictions by averaging\n",
        "    adam_pred = adam_model.predict(X_test)\n",
        "    sgd_pred = sgd_model.predict(X_test)\n",
        "    rprop_pred = rprop_model.predict(X_test)\n",
        "\n",
        "    # Average predictions from the models\n",
        "    ensemble_pred = (adam_pred + sgd_pred + rprop_pred) / 3\n",
        "    ensemble_pred = np.argmax(ensemble_pred, axis=1)  # Assuming classification\n",
        "\n",
        "    y_test_labels = np.argmax(y_test, axis=1)  # Get true labels\n",
        "    accuracy = np.mean(ensemble_pred == y_test_labels)\n",
        "\n",
        "    print(f\"Ensemble model accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfVjQbQH2hQU"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    X, y = load_data('Almond.csv')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_test = preprocess_data(X_train, X_test)\n",
        "\n",
        "    best_model = perform_grid_search(X_train, y_train)\n",
        "    train_and_compare_algorithms(X_train, y_train, X_test, y_test)\n",
        "    hybrid_learning(X_train, y_train, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZwBXj0QgOmPST9YRDUrSF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}