{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazbengu/COS711-ASSIGNMENT-TWO/blob/main/Joy_Bengu_25000307_COS711_Assignment_Two_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YrD_3efB3VAd",
        "collapsed": true,
        "outputId": "b5e38ada-8de1-4cc6-bbbf-b0233b13f268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Collecting keras>=3.2.0 (from scikeras)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "Successfully installed keras-3.6.0\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
            "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow)\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting setuptools (from tensorflow)\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow)\n",
            "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rich (from keras>=3.2.0->tensorflow)\n",
            "  Downloading rich-13.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.2.0->tensorflow)\n",
            "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.2.0->tensorflow)\n",
            "  Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
            "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.2.0->tensorflow)\n",
            "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m219.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
            "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
            "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
            "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, optree, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, tensorboard, rich, keras, tensorflow\n",
            "  Attempting uninstall: namex\n",
            "    Found existing installation: namex 0.0.8\n",
            "    Uninstalling namex-0.0.8:\n",
            "      Successfully uninstalled namex-0.0.8\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.44.0\n",
            "    Uninstalling wheel-0.44.0:\n",
            "      Successfully uninstalled wheel-0.44.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.4.0\n",
            "    Uninstalling termcolor-2.4.0:\n",
            "      Successfully uninstalled termcolor-2.4.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.4\n",
            "    Uninstalling Werkzeug-3.0.4:\n",
            "      Successfully uninstalled Werkzeug-3.0.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: optree\n",
            "    Found existing installation: optree 0.12.1\n",
            "    Uninstalling optree-0.12.1:\n",
            "      Successfully uninstalled optree-0.12.1\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.11.0\n",
            "    Uninstalling h5py-3.11.0:\n",
            "      Successfully uninstalled h5py-3.11.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.8.1\n",
            "    Uninstalling rich-13.8.1:\n",
            "      Successfully uninstalled rich-13.8.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.6.0\n",
            "    Uninstalling keras-3.6.0:\n",
            "      Successfully uninstalled keras-3.6.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 idna-3.10 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.0 packaging-24.1 protobuf-4.25.5 pygments-2.18.0 requests-2.32.3 rich-13.9.1 setuptools-75.1.0 six-1.16.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 typing-extensions-4.12.2 urllib3-2.2.3 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "absl",
                  "astunparse",
                  "certifi",
                  "charset_normalizer",
                  "flatbuffers",
                  "gast",
                  "h5py",
                  "ml_dtypes",
                  "pkg_resources",
                  "requests",
                  "setuptools",
                  "six",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "1c7c970085cd4483bd11ce1a75e5ba6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.11.0\n",
            "  Using cached keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.6.0\n",
            "    Uninstalling keras-3.6.0:\n",
            "      Successfully uninstalled keras-3.6.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    installed = install_given_reqs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/__init__.py\", line 70, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 851, in install\n",
            "    install_wheel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/install/wheel.py\", line 726, in install_wheel\n",
            "    _install_wheel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/install/wheel.py\", line 584, in _install_wheel\n",
            "    file.save()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/install/wheel.py\", line 382, in save\n",
            "    shutil.copyfileobj(f, dest)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 198, in copyfileobj\n",
            "    fdst_write(buf)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 521, in Union\n",
            "    return _UnionGenericAlias(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1025, in __init__\n",
            "    self.__parameters__ = _collect_type_vars(params, typevar_types=_typevar_types)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "!pip install --force-reinstall tensorflow\n",
        "!pip install --force-reinstall keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "ub8o5M6J18ES",
        "outputId": "701d5e46-9c75-4d29-f747-db65aeefedae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'distribute' from partially initialized module 'keras' (most likely due to a circular import) (/usr/local/lib/python3.10/dist-packages/keras/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-056956431c1b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/api/_v2/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'distribute' from partially initialized module 'keras' (most likely due to a circular import) (/usr/local/lib/python3.10/dist-packages/keras/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.optimizers import Optimizer\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "8hKOKPFT2tzY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    data.iloc[:, :-1] = imputer.fit_transform(data.iloc[:, :-1])  # Assuming last column is labels\n",
        "\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "\n",
        "    y = pd.get_dummies(y).values\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RProp(Optimizer):\n",
        "    def __init__(self, learning_rate=0.01, eta_plus=1.2, eta_minus=0.5,\n",
        "                 delta_min=1e-6, delta_max=50, **kwargs):\n",
        "\n",
        "        # Pass learning_rate to superclass\n",
        "        kwargs['learning_rate'] = learning_rate\n",
        "        super(RProp, self).__init__(**kwargs)\n",
        "\n",
        "        self.eta_plus = eta_plus\n",
        "        self.eta_minus = eta_minus\n",
        "        self.delta_min = delta_min\n",
        "        self.delta_max = delta_max\n",
        "\n",
        "        # Initialize step sizes for each parameter\n",
        "        self._step_sizes = {}\n",
        "        self.eta_plus = eta_plus\n",
        "        self.eta_minus = eta_minus\n",
        "        self.delta_min = delta_min\n",
        "        self.delta_max = delta_max\n",
        "        self._delta_zero = K.constant(0.1)\n",
        "\n",
        "\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        # This is a basic implementation, and might need to be adapted\n",
        "        # depending on your specific use case and TensorFlow version.\n",
        "\n",
        "        # Get the update operation from the get_updates method\n",
        "        update_op = self.get_updates(None, [var])[0]  # Assuming only one variable\n",
        "\n",
        "        # Execute the update operation\n",
        "        self._distribution_strategy.extended.update(\n",
        "            var, lambda: update_op, group=False\n",
        "        )\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
        "        # Get step size for the variable\n",
        "        step_size = self.get_slot(var, 'step_size')\n",
        "\n",
        "        # Gather relevant step sizes based on indices\n",
        "        gathered_step_sizes = tf.gather(step_size, indices)\n",
        "\n",
        "        # Calculate updates\n",
        "        updates = -K.sign(grad) * gathered_step_sizes\n",
        "\n",
        "        # Apply updates to the variable\n",
        "        var.assign(tf.tensor_scatter_nd_update(var, tf.expand_dims(indices, axis=-1), updates))\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        shapes = [K.int_shape(p) for p in params]\n",
        "        deltas = [K.zeros(shape) for shape in shapes]\n",
        "        grad_prevs = [K.zeros(shape) for shape in shapes]\n",
        "\n",
        "        for p, g, delta, grad_prev in zip(params, grads, deltas, grad_prevs):\n",
        "            change = K.sign(g * grad_prev)\n",
        "\n",
        "            new_delta = K.switch(\n",
        "                K.equal(change, 1),\n",
        "                K.minimum(delta * self.eta_plus, self.delta_max),\n",
        "                K.switch(\n",
        "                    K.equal(change, -1),\n",
        "                    K.maximum(delta * self.eta_minus, self.delta_min),\n",
        "                    self._delta_zero\n",
        "                )\n",
        "            )\n",
        "\n",
        "            update = -K.sign(g) * new_delta\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                update = p.constraint(update)\n",
        "\n",
        "            self.updates.append(K.update(p, p + update))\n",
        "            self.updates.append(K.update(delta, new_delta))\n",
        "            self.updates.append(K.update(grad_prev, g))\n",
        "\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(RProp, self).get_config()\n",
        "        config.update({\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'eta_plus': self.eta_plus,\n",
        "            'eta_minus': self.eta_minus,\n",
        "            'delta_min': self.delta_min,\n",
        "            'delta_max': self.delta_max\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "HH8yvDTKttY0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PgrMZoS22txz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_model(optimizer='adam', learning_rate=0.001, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=13, activation=activation))  # 12 input features\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dense(3, activation='softmax'))  # 3 classes\n",
        "\n",
        "    # Initialize the optimizer based on the chosen or default optimizer type\n",
        "    if optimizer == 'adam':\n",
        "        # Providing a default learning rate for Adam if not specified\n",
        "        learning_rate = learning_rate or 0.001\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        # Providing a default learning rate for SGD if not specified\n",
        "        learning_rate = learning_rate or 0.001\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    elif optimizer == 'rprop':  # Use RProp Optimizer\n",
        "       opt = RProp(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer type\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "l64YbG4F2qVb"
      },
      "outputs": [],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "def perform_grid_search(X_train, y_train):\n",
        "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "    param_grid = {\n",
        "        'batch_size': [5, 10, 20],\n",
        "        'epochs': [5, 10]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "    grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "    # Plotting results\n",
        "    results_df = pd.DataFrame(grid_result.cv_results_)\n",
        "    results_pivot = results_df.pivot_table(index='param_batch_size', columns='param_epochs', values='mean_test_score')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(results_pivot, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
        "    plt.title(\"Hyperparameter Tuning: Batch Size vs Epochs\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Batch Size\")\n",
        "    plt.show()\n",
        "\n",
        "    return grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TOYstehSbuM7"
      },
      "outputs": [],
      "source": [
        "def train_and_compare_algorithms(X_train, y_train, X_test, y_test):\n",
        "    adam_model = create_model(optimizer='adam', learning_rate=0.001)\n",
        "    history_adam = adam_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    sgd_model = create_model(optimizer='sgd', learning_rate=0.001)\n",
        "    history_sgd = sgd_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    rprop_model = create_model(optimizer='rprop', learning_rate=0.001)\n",
        "    history_rprop = rprop_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=20)\n",
        "\n",
        "    plt.plot(history_adam.history['val_loss'], label='Adam')\n",
        "    plt.plot(history_sgd.history['val_loss'], label='SGD')\n",
        "    plt.plot(history_rprop.history['val_loss'], label='Rprop')\n",
        "    plt.title('Validation Loss Comparison')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8Y2MwLlv2juY"
      },
      "outputs": [],
      "source": [
        "def hybrid_learning(X_train, y_train, X_test, y_test):\n",
        "    # Train individual models\n",
        "    adam_model = create_model(optimizer='adam', learning_rate=0.001)\n",
        "    adam_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    sgd_model = create_model(optimizer='sgd', learning_rate=0.001)\n",
        "    sgd_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    rprop_model = create_model(optimizer='rprop')\n",
        "    rprop_model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    # Ensemble predictions by averaging\n",
        "    adam_pred = adam_model.predict(X_test)\n",
        "    sgd_pred = sgd_model.predict(X_test)\n",
        "    rprop_pred = rprop_model.predict(X_test)\n",
        "\n",
        "    # Average predictions from the models\n",
        "    ensemble_pred = (adam_pred + sgd_pred + rprop_pred) / 3\n",
        "    ensemble_pred = np.argmax(ensemble_pred, axis=1)  # Assuming classification\n",
        "\n",
        "    y_test_labels = np.argmax(y_test, axis=1)  # Get true labels\n",
        "    accuracy = np.mean(ensemble_pred == y_test_labels)\n",
        "\n",
        "    print(f\"Ensemble model accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "cfVjQbQH2hQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c695728b-3c51-4533-c1f5-8f02c77ad906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.9589618127888858 using {'batch_size': 5, 'epochs': 10}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.8423 - val_accuracy: 0.7914 - val_loss: 0.5474\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.5515 - val_accuracy: 0.8538 - val_loss: 0.4323\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.4332 - val_accuracy: 0.8841 - val_loss: 0.3467\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8684 - loss: 0.3629 - val_accuracy: 0.8984 - val_loss: 0.2884\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2573 - val_accuracy: 0.9162 - val_loss: 0.2335\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.2325 - val_accuracy: 0.9287 - val_loss: 0.2176\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1757 - val_accuracy: 0.9394 - val_loss: 0.1660\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9460 - loss: 0.1523 - val_accuracy: 0.9109 - val_loss: 0.1821\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.1363 - val_accuracy: 0.9519 - val_loss: 0.1411\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.1088 - val_accuracy: 0.9590 - val_loss: 0.1240\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9700 - loss: 0.0968 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0868 - val_accuracy: 0.9661 - val_loss: 0.1008\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0705 - val_accuracy: 0.9733 - val_loss: 0.0884\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0624 - val_accuracy: 0.9715 - val_loss: 0.0838\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0604 - val_accuracy: 0.9697 - val_loss: 0.0840\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0451 - val_accuracy: 0.9804 - val_loss: 0.0724\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0407 - val_accuracy: 0.9786 - val_loss: 0.0736\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0376 - val_accuracy: 0.9804 - val_loss: 0.0593\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0350 - val_accuracy: 0.9697 - val_loss: 0.0776\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0381 - val_accuracy: 0.9840 - val_loss: 0.0529\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3670 - loss: 1.1133 - val_accuracy: 0.4296 - val_loss: 1.0863\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4323 - loss: 1.0758 - val_accuracy: 0.4777 - val_loss: 1.0516\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4919 - loss: 1.0435 - val_accuracy: 0.5258 - val_loss: 1.0234\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5368 - loss: 1.0128 - val_accuracy: 0.5722 - val_loss: 0.9989\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5642 - loss: 0.9888 - val_accuracy: 0.6025 - val_loss: 0.9780\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5699 - loss: 0.9659 - val_accuracy: 0.6150 - val_loss: 0.9588\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.9497 - val_accuracy: 0.6275 - val_loss: 0.9416\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.9352 - val_accuracy: 0.6381 - val_loss: 0.9258\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6136 - loss: 0.9163 - val_accuracy: 0.6399 - val_loss: 0.9112\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.9090 - val_accuracy: 0.6471 - val_loss: 0.8976\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 0.8847 - val_accuracy: 0.6560 - val_loss: 0.8846\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 0.8857 - val_accuracy: 0.6720 - val_loss: 0.8726\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 0.8781 - val_accuracy: 0.6809 - val_loss: 0.8608\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6636 - loss: 0.8616 - val_accuracy: 0.6970 - val_loss: 0.8494\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.8453 - val_accuracy: 0.7023 - val_loss: 0.8388\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.8284 - val_accuracy: 0.7094 - val_loss: 0.8284\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.8367 - val_accuracy: 0.7077 - val_loss: 0.8184\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.8166 - val_accuracy: 0.7130 - val_loss: 0.8088\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.8005 - val_accuracy: 0.7184 - val_loss: 0.7995\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.7978 - val_accuracy: 0.7201 - val_loss: 0.7906\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-849388715a99>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-849388715a99>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_and_compare_algorithms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mhybrid_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-a396262708e6>\u001b[0m in \u001b[0;36mtrain_and_compare_algorithms\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrprop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhistory_rprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrprop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_adam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    X, y = load_data('Almond.csv')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_test = preprocess_data(X_train, X_test)\n",
        "\n",
        "    best_model = perform_grid_search(X_train, y_train)\n",
        "    train_and_compare_algorithms(X_train, y_train, X_test, y_test)\n",
        "    hybrid_learning(X_train, y_train, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnByr0X5TxjVY1ylqoa7Wd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}